Running Distributed Services at Scale in the Cloud
===================================================
http://events.linuxfoundation.org/events/linuxcon-north-america/program/schedule

Docker  - > lightweight/portable. Alternative to images/VDKs
	- A lot of flexibility because they're lightweight
        - Portable, flexible, fast, efficient

Why decompose BIG services into microservices?
    - Easily scalable up and down
    - Easier to separate development teams into smaller chunks
    - Run components individually
    - "Smaller blast radius" for changes

Containers natural to move to microservices
    - Any app, any language
    - Image is the version
    - test and deploy the same artifact
    - stateless servers decress change risk

Container pipeline:

    - utilities/patches --> BASE IMAGE  
    -- update Docker/container image with new patches, etc. 
    <add graphic here>

Service discovery

    - Load Balancers
    - DNS
    - Service discovery services
        - Eureka <-- check this out
        - blogs on AWS site RE: this stuff

Monitoring & Logging

    - Docker logs
        - Log streams

Cluster Management

    - Managing one resource is straightforward, complexity at scale
    - Check out "Jenkins"
    - Fleet management
        - monitor utilization
        - grow capacity
            - when demand dictates
        - security

State Management

    - Container state and the cluster state
    - Key/value stores
    - Active state management is critical to managing a cluster
        - eventually you'll want to think about scheduling
        - Think about what constraints a cluster has

EC2 Container service

    - Amazon ECS <-- don't need to run anything yourself :)
    - AWS control panel
    - Key/value store that does all the state management
    - Nothing to run, complete state, control and monitoring, scale 
    - Flexible container placement - batch jobs, application, multiple schedulers
    - Integration with AWS services
        - Idea is to focus on the containers themselves rather than the infrastructure

    - Task definitions <-- how much memory/CPU, what containers are needed? Where are the images coming from?
    - Docker YAML?
    - Creating task definition is the same as `docker run`
    - Provisions containers onto instances, registers them with load balancer
    - Service gives you the ability to update the task definition, e.g. updating OS version, etc. 

Custom Schedulers

    - Marathon or Chronos instead

Walkthrough

    - I want to run a service
    - Provision some capacity
    - Declare the resources in a task definition
    - Create a service "I want to run x number of those task definition"
    - Define space on the fleet to run those task definitions <---usually behind a load-balancer


Key value store = transactional journal
